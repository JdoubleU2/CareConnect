{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.17870439314966494,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0029784065524944155,
      "grad_norm": 5.2895121574401855,
      "learning_rate": 4e-05,
      "loss": 6.0913,
      "step": 1
    },
    {
      "epoch": 0.005956813104988831,
      "grad_norm": 5.906484127044678,
      "learning_rate": 8e-05,
      "loss": 5.3054,
      "step": 2
    },
    {
      "epoch": 0.008935219657483246,
      "grad_norm": 4.800806045532227,
      "learning_rate": 0.00012,
      "loss": 5.8428,
      "step": 3
    },
    {
      "epoch": 0.011913626209977662,
      "grad_norm": Infinity,
      "learning_rate": 0.00012,
      "loss": 6.5811,
      "step": 4
    },
    {
      "epoch": 0.014892032762472078,
      "grad_norm": 6.463045597076416,
      "learning_rate": 0.00016,
      "loss": 4.7932,
      "step": 5
    },
    {
      "epoch": 0.017870439314966492,
      "grad_norm": 6.46223258972168,
      "learning_rate": 0.0002,
      "loss": 3.9381,
      "step": 6
    },
    {
      "epoch": 0.02084884586746091,
      "grad_norm": 5.861394882202148,
      "learning_rate": 0.00019636363636363636,
      "loss": 3.1698,
      "step": 7
    },
    {
      "epoch": 0.023827252419955324,
      "grad_norm": 6.5897417068481445,
      "learning_rate": 0.00019272727272727274,
      "loss": 1.8186,
      "step": 8
    },
    {
      "epoch": 0.02680565897244974,
      "grad_norm": 7.130115509033203,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.5284,
      "step": 9
    },
    {
      "epoch": 0.029784065524944156,
      "grad_norm": 5.477110862731934,
      "learning_rate": 0.00018545454545454545,
      "loss": 0.9199,
      "step": 10
    },
    {
      "epoch": 0.03276247207743857,
      "grad_norm": 8.226783752441406,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.3814,
      "step": 11
    },
    {
      "epoch": 0.035740878629932984,
      "grad_norm": 2.949817180633545,
      "learning_rate": 0.0001781818181818182,
      "loss": 0.5727,
      "step": 12
    },
    {
      "epoch": 0.0387192851824274,
      "grad_norm": 3.1519370079040527,
      "learning_rate": 0.00017454545454545454,
      "loss": 0.8176,
      "step": 13
    },
    {
      "epoch": 0.04169769173492182,
      "grad_norm": 4.907687187194824,
      "learning_rate": 0.0001709090909090909,
      "loss": 0.4944,
      "step": 14
    },
    {
      "epoch": 0.044676098287416234,
      "grad_norm": 3.8264098167419434,
      "learning_rate": 0.00016727272727272728,
      "loss": 0.8541,
      "step": 15
    },
    {
      "epoch": 0.04765450483991065,
      "grad_norm": 2.148240327835083,
      "learning_rate": 0.00016363636363636366,
      "loss": 0.3101,
      "step": 16
    },
    {
      "epoch": 0.05063291139240506,
      "grad_norm": 4.067953586578369,
      "learning_rate": 0.00016,
      "loss": 1.2069,
      "step": 17
    },
    {
      "epoch": 0.05361131794489948,
      "grad_norm": 3.765439033508301,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.3986,
      "step": 18
    },
    {
      "epoch": 0.05658972449739389,
      "grad_norm": 3.1210057735443115,
      "learning_rate": 0.00015272727272727275,
      "loss": 0.9269,
      "step": 19
    },
    {
      "epoch": 0.05956813104988831,
      "grad_norm": 2.8542168140411377,
      "learning_rate": 0.0001490909090909091,
      "loss": 0.8361,
      "step": 20
    },
    {
      "epoch": 0.06254653760238273,
      "grad_norm": 2.118644952774048,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.5962,
      "step": 21
    },
    {
      "epoch": 0.06552494415487714,
      "grad_norm": 3.7008657455444336,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.137,
      "step": 22
    },
    {
      "epoch": 0.06850335070737155,
      "grad_norm": 4.413452625274658,
      "learning_rate": 0.0001381818181818182,
      "loss": 0.714,
      "step": 23
    },
    {
      "epoch": 0.07148175725986597,
      "grad_norm": 2.921975612640381,
      "learning_rate": 0.00013454545454545455,
      "loss": 1.2242,
      "step": 24
    },
    {
      "epoch": 0.07446016381236038,
      "grad_norm": 0.9507786631584167,
      "learning_rate": 0.00013090909090909093,
      "loss": 0.1098,
      "step": 25
    },
    {
      "epoch": 0.0774385703648548,
      "grad_norm": 2.540339946746826,
      "learning_rate": 0.00012727272727272728,
      "loss": 0.3437,
      "step": 26
    },
    {
      "epoch": 0.08041697691734921,
      "grad_norm": 1.5207093954086304,
      "learning_rate": 0.00012363636363636364,
      "loss": 0.2029,
      "step": 27
    },
    {
      "epoch": 0.08339538346984364,
      "grad_norm": 2.081936836242676,
      "learning_rate": 0.00012,
      "loss": 0.4423,
      "step": 28
    },
    {
      "epoch": 0.08637379002233805,
      "grad_norm": 2.2684848308563232,
      "learning_rate": 0.00011636363636363636,
      "loss": 0.3809,
      "step": 29
    },
    {
      "epoch": 0.08935219657483247,
      "grad_norm": 2.3013901710510254,
      "learning_rate": 0.00011272727272727272,
      "loss": 0.3677,
      "step": 30
    },
    {
      "epoch": 0.09233060312732688,
      "grad_norm": 3.5756208896636963,
      "learning_rate": 0.00010909090909090909,
      "loss": 0.9904,
      "step": 31
    },
    {
      "epoch": 0.0953090096798213,
      "grad_norm": 2.1048030853271484,
      "learning_rate": 0.00010545454545454545,
      "loss": 0.2141,
      "step": 32
    },
    {
      "epoch": 0.09828741623231571,
      "grad_norm": 2.0985214710235596,
      "learning_rate": 0.00010181818181818181,
      "loss": 0.4698,
      "step": 33
    },
    {
      "epoch": 0.10126582278481013,
      "grad_norm": 2.290113687515259,
      "learning_rate": 9.818181818181818e-05,
      "loss": 0.4201,
      "step": 34
    },
    {
      "epoch": 0.10424422933730454,
      "grad_norm": 1.9020699262619019,
      "learning_rate": 9.454545454545455e-05,
      "loss": 0.219,
      "step": 35
    },
    {
      "epoch": 0.10722263588979895,
      "grad_norm": 3.769045352935791,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.0612,
      "step": 36
    },
    {
      "epoch": 0.11020104244229337,
      "grad_norm": 3.515321731567383,
      "learning_rate": 8.727272727272727e-05,
      "loss": 0.8634,
      "step": 37
    },
    {
      "epoch": 0.11317944899478778,
      "grad_norm": 3.8547401428222656,
      "learning_rate": 8.363636363636364e-05,
      "loss": 1.3722,
      "step": 38
    },
    {
      "epoch": 0.11615785554728221,
      "grad_norm": 1.0219848155975342,
      "learning_rate": 8e-05,
      "loss": 0.0641,
      "step": 39
    },
    {
      "epoch": 0.11913626209977662,
      "grad_norm": 3.253681182861328,
      "learning_rate": 7.636363636363637e-05,
      "loss": 0.5415,
      "step": 40
    },
    {
      "epoch": 0.12211466865227104,
      "grad_norm": 2.2923452854156494,
      "learning_rate": 7.272727272727273e-05,
      "loss": 0.2151,
      "step": 41
    },
    {
      "epoch": 0.12509307520476545,
      "grad_norm": 2.8150014877319336,
      "learning_rate": 6.90909090909091e-05,
      "loss": 0.3346,
      "step": 42
    },
    {
      "epoch": 0.12807148175725985,
      "grad_norm": 2.6121151447296143,
      "learning_rate": 6.545454545454546e-05,
      "loss": 0.4091,
      "step": 43
    },
    {
      "epoch": 0.13104988830975428,
      "grad_norm": 2.172563076019287,
      "learning_rate": 6.181818181818182e-05,
      "loss": 0.301,
      "step": 44
    },
    {
      "epoch": 0.1340282948622487,
      "grad_norm": 3.404642343521118,
      "learning_rate": 5.818181818181818e-05,
      "loss": 0.8147,
      "step": 45
    },
    {
      "epoch": 0.1370067014147431,
      "grad_norm": 2.731489896774292,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.4764,
      "step": 46
    },
    {
      "epoch": 0.13998510796723754,
      "grad_norm": 2.0334579944610596,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.3023,
      "step": 47
    },
    {
      "epoch": 0.14296351451973194,
      "grad_norm": 2.1512773036956787,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 0.213,
      "step": 48
    },
    {
      "epoch": 0.14594192107222637,
      "grad_norm": 2.624673366546631,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 0.579,
      "step": 49
    },
    {
      "epoch": 0.14892032762472077,
      "grad_norm": 2.724390983581543,
      "learning_rate": 4e-05,
      "loss": 0.5815,
      "step": 50
    },
    {
      "epoch": 0.1518987341772152,
      "grad_norm": 2.6829729080200195,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.6222,
      "step": 51
    },
    {
      "epoch": 0.1548771407297096,
      "grad_norm": 2.301231861114502,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.2589,
      "step": 52
    },
    {
      "epoch": 0.15785554728220402,
      "grad_norm": 1.932873010635376,
      "learning_rate": 2.909090909090909e-05,
      "loss": 0.2058,
      "step": 53
    },
    {
      "epoch": 0.16083395383469842,
      "grad_norm": 2.311023235321045,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 0.2039,
      "step": 54
    },
    {
      "epoch": 0.16381236038719285,
      "grad_norm": 2.2366740703582764,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.2763,
      "step": 55
    },
    {
      "epoch": 0.16679076693968728,
      "grad_norm": 2.774247407913208,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.3498,
      "step": 56
    },
    {
      "epoch": 0.16976917349218168,
      "grad_norm": 2.958259105682373,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.5844,
      "step": 57
    },
    {
      "epoch": 0.1727475800446761,
      "grad_norm": 2.4227232933044434,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.4083,
      "step": 58
    },
    {
      "epoch": 0.1757259865971705,
      "grad_norm": 1.9342420101165771,
      "learning_rate": 7.272727272727272e-06,
      "loss": 0.2067,
      "step": 59
    },
    {
      "epoch": 0.17870439314966494,
      "grad_norm": 2.9031240940093994,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.9093,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2045502962221056.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
